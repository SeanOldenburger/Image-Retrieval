{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2 as cv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import imageio\n",
    "from PIL import Image\n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in all the Images, filenames and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_from_folder(folder, image_type, gray=False):\n",
    "    images = []\n",
    "    filenames = []\n",
    "    y = []\n",
    "    category, idx = \"none\", 0\n",
    "    for filename in sorted(os.listdir(folder)):\n",
    "        if filename.endswith(image_type):\n",
    "            if image_type == \".gif\":\n",
    "                gif_image = cv.VideoCapture(os.path.join(folder, filename))\n",
    "                ret, frame = gif_image.read()\n",
    "                image = Image.fromarray(frame)\n",
    "                image = np.array(image)\n",
    "            else:\n",
    "                image = cv.imread(os.path.join(folder, filename))\n",
    "            if gray:\n",
    "                gray_image = image\n",
    "            else:\n",
    "                gray_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "            if gray_image is not None:\n",
    "                images.append(gray_image)\n",
    "                split_name = filename.split('_')\n",
    "                if len(split_name) == 3:\n",
    "                    fname = filename.split('_')[0] + \"_\" + filename.split('_')[1]\n",
    "                elif len(split_name) == 2:\n",
    "                    fname = filename.split('_')[0]\n",
    "                elif len(split_name) == 1:\n",
    "                    fname = filename.split('-')[0]\n",
    "                filenames.append(fname)\n",
    "                if filename.startswith(category):\n",
    "                    y.append(idx)\n",
    "                else:\n",
    "                    split = filename.split('_')\n",
    "                    if len(split) == 3:\n",
    "                        category = filename.split('_')[0] + \"_\" + filename.split('_')[1]\n",
    "                    elif len(split) == 2:\n",
    "                        category = filename.split('_')[0]\n",
    "                    idx = idx + 1\n",
    "                    y.append(idx)\n",
    "    print(len(images), \"Images loaded successfully!\")\n",
    "    return images, filenames, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute SIFT features (keypoints & descriptors) on each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SIFT(images):\n",
    "    sift = cv.SIFT_create()\n",
    "    \n",
    "    keypoints_per_image = []\n",
    "    descriptor_per_image = []\n",
    "    \n",
    "    count = 0\n",
    "    for image in images:\n",
    "        keypoints, descriptor = sift.detectAndCompute(image, None)\n",
    "\n",
    "        keypoints_per_image.append(keypoints)\n",
    "        descriptor_per_image.append(descriptor)\n",
    "        \n",
    "        count += 1 \n",
    "        clear_output(wait=True)\n",
    "        print(\"Percentage Completed: {}%\".format(round((count/len(images))*100), 2))\n",
    "    \n",
    "    return keypoints_per_image, descriptor_per_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack the descriptors into 1 array for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_descriptors(descriptors):\n",
    "    stack = []\n",
    "    \n",
    "    for desc in descriptors:\n",
    "        tmp = np.array(desc)\n",
    "        if tmp.shape:\n",
    "            stack.append(tmp)\n",
    "            \n",
    "    all_descriptors = np.vstack(i for i in stack)\n",
    "    \n",
    "    return all_descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering the descriptors (either using kmeans or minibatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster(data, n_clusters=100, cluster_type=\"minibatch\"):\n",
    "    start = time.time()\n",
    "    \n",
    "    if cluster_type == \"minibatch\":\n",
    "        cluster = MiniBatchKMeans(n_clusters=n_clusters)\n",
    "        y_cluster = cluster.fit_predict(data)\n",
    "    elif cluster_type == \"kmeans\":\n",
    "        cluster = KMeans(n_clusters=n_clusters)\n",
    "        y_cluster = cluster.fit_predict(data)\n",
    "    else:\n",
    "        print(\"Unknown cluster_type! Try: 'minibatch' or 'kmeans'\")\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Time Elapsed: {} min\".format(round((end - start)/60, 2)))\n",
    "    return y_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Bag-Of-Words array for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_BoW(descriptors, y_cluster, n_clusters):\n",
    "    previous = 0\n",
    "    count = 0\n",
    "    image_words = []\n",
    "    for image_number in range(len(descriptors)):\n",
    "        if descriptors[image_number] is not None:\n",
    "            number_of_keypoints = len(descriptors[image_number])\n",
    "            image_words.append(y_cluster[previous:number_of_keypoints+previous])\n",
    "            previous = number_of_keypoints\n",
    "            \n",
    "            count += 1\n",
    "            clear_output(wait=True)\n",
    "            print(\"(1/2) Percentage Completed: {}%\".format(round((count/len(descriptors))*100), 2))\n",
    "        else:\n",
    "            # If image has no desciptors, append 0 words to it\n",
    "            image_words.append([0])\n",
    "\n",
    "    count = 0\n",
    "    image_histograms = []\n",
    "    for image in range(len(image_words)):\n",
    "        hist = [0]*n_clusters\n",
    "        for words in image_words[image]:\n",
    "            hist[words-1] = hist[words-1]+1\n",
    "        image_histograms.append(hist)\n",
    "        \n",
    "        count += 1\n",
    "        clear_output(wait=True)\n",
    "        print(\"(2/2) Percentage Completed: {}%\".format(round((count/len(image_words))*100), 2))\n",
    "    \n",
    "    return image_histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OXFORD 5k DATASET:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Images\n",
    "folder = r\"C:\\Users\\Sean\\Desktop\\Image-Retrieval\\Oxford code\\Oxford dataset\\Oxford building images\"\n",
    "images, filenames, y = load_image_from_folder(folder, \".jpg\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIFT features\n",
    "keypoints_per_image, descriptor_per_image = SIFT(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking descriptors\n",
    "stacked_desriptors = stack_descriptors(descriptor_per_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering descriptors\n",
    "n_clusters = 1000\n",
    "y_clusters = cluster(stacked_desriptors, n_clusters, \"minibatch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating BoW for each image\n",
    "oxford_5k_image_histograms = solve_BoW(descriptor_per_image, y_clusters, n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving BoW array\n",
    "np.save('Oxford5k_BoW_words={}.npy'.format(n_clusters), oxford_5k_image_histograms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MPEG7 DATASET:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Images\n",
    "folder2 = r\"C:\\Users\\Sean\\Desktop\\Image-Retrieval\\MPEG7 code\\MPEG7\"\n",
    "images2, filenames2, y2 = load_image_from_folder(folder2, \".gif\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIFT features\n",
    "keypoints_per_image2, descriptor_per_image2 = SIFT(images2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking descriptors\n",
    "stacked_desriptors2 = stack_descriptors(descriptor_per_image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering descriptors\n",
    "n_clusters2 = 1000\n",
    "y_clusters2 = cluster(stacked_desriptors2, n_clusters2, \"minibatch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating BoW for each image\n",
    "MPEG7_image_histograms = solve_BoW(descriptor_per_image2, y_clusters2, n_clusters2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving BoW array\n",
    "np.save('MPEG7_BoW_words={}.npy'.format(n_clusters2), MPEG7_image_histograms)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
