{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oxford5k + MPEG7 Image Retrieval:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean version of all functions used to compute the metrics/Image retrieval of either MPEG7 or Oxford5k dataset\n",
    "\n",
    "At the bottom of the page is the functions to run them, and instructions on inputted variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import pandas\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in Oxford Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data(images_path, gt_path):\n",
    "    test_images_path = []\n",
    "    test_names = []\n",
    "    test_gray_images = []\n",
    "    test_colour_images = []\n",
    "    \n",
    "    for filename in sorted(os.listdir(gt_path)):\n",
    "        if filename.endswith(\"query.txt\"):\n",
    "            \n",
    "            # Saving filename\n",
    "            tmp = filename.split(\".\")[0].split(\"_\")\n",
    "            if len(tmp) == 4:\n",
    "                name = tmp[0]+\"_\"+tmp[1]\n",
    "            elif len(tmp) == 3:\n",
    "                name = tmp[0]\n",
    "            test_names.append(name)\n",
    "\n",
    "            # Reading the image number to be saved\n",
    "            with open(os.path.join(gt_path, filename), \"r\") as f:\n",
    "                line = f.readline()\n",
    "                test_images_path.append(line.split(\" \")[0])\n",
    "    \n",
    "    for path in test_images_path:\n",
    "        image = cv2.imread(os.path.join(images_path, path[5:]) + \".jpg\")\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        test_gray_images.append(gray_image)\n",
    "        test_colour_images.append(image)\n",
    "    \n",
    "    print(\"Loaded in {} Images!\".format(len(test_gray_images)))\n",
    "    \n",
    "    return test_gray_images, test_colour_images, test_names, test_images_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in Oxford Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data(images_path, gt_path, test_img_paths):\n",
    "    train_names = []\n",
    "    train_images_path = []\n",
    "    train_gray_images = []\n",
    "    train_colour_images = []\n",
    "\n",
    "    all_image_names = []\n",
    "\n",
    "    for filename in sorted(os.listdir(gt_path)):\n",
    "        if filename.endswith(\"good.txt\") or filename.endswith(\"ok.txt\"):\n",
    "\n",
    "            # Saving filenames\n",
    "            tmp = filename.split(\".\")[0].split(\"_\")\n",
    "            if len(tmp) == 4:\n",
    "                name = tmp[0]+\"_\"+tmp[1]\n",
    "            elif len(tmp) == 3:\n",
    "                name = tmp[0]\n",
    "\n",
    "            # Saving image paths\n",
    "            with open(os.path.join(gt_path, filename), \"r\") as f:\n",
    "                line = f.readlines()\n",
    "                for i in range(len(line)):\n",
    "                    line[i] = line[i][:-1]\n",
    "                    if line[i] not in all_image_names:\n",
    "                        if \"oxc1_\"+str(line[i]) not in test_img_paths:\n",
    "                            # Append this many names\n",
    "                            train_names.append(name)\n",
    "                            train_images_path.append(line[i])\n",
    "                            all_image_names.append(line[i])\n",
    "\n",
    "    for path in train_images_path:\n",
    "        image = cv2.imread(os.path.join(images_path, path) + \".jpg\")\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        train_gray_images.append(gray_image)\n",
    "        train_colour_images.append(image)\n",
    "    \n",
    "    print(\"Loaded in {} Images!\".format(len(train_gray_images)))\n",
    "    \n",
    "    return train_gray_images, train_colour_images, train_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in MPEG7 function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_MPEG7_data(folder, image_type, gray=False):\n",
    "    images = []\n",
    "    filenames = []\n",
    "    y = []\n",
    "    category, idx = \"none\", 0\n",
    "    for filename in sorted(os.listdir(folder)):\n",
    "        if filename.endswith(image_type):\n",
    "            if image_type == \".gif\":\n",
    "                gif_image = cv2.VideoCapture(os.path.join(folder, filename))\n",
    "                ret, frame = gif_image.read()\n",
    "                image = Image.fromarray(frame)\n",
    "                image = image.resize((32, 32), Image.ANTIALIAS)\n",
    "                image = np.array(image)\n",
    "            else:\n",
    "                image = cv2.imread(os.path.join(folder, filename))\n",
    "            if gray:\n",
    "                gray_image = image\n",
    "            else:\n",
    "                gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            if gray_image is not None:\n",
    "                images.append(gray_image)\n",
    "                split_name = filename.split('_')\n",
    "                if len(split_name) == 3:\n",
    "                    fname = filename.split('_')[0] + \"_\" + filename.split('_')[1]\n",
    "                elif len(split_name) == 2:\n",
    "                    fname = filename.split('_')[0]\n",
    "                elif len(split_name) == 1:\n",
    "                    fname = filename.split('-')[0]\n",
    "                filenames.append(fname)\n",
    "                if filename.startswith(category):\n",
    "                    y.append(idx)\n",
    "                else:\n",
    "                    split = filename.split('_')\n",
    "                    if len(split) == 3:\n",
    "                        category = filename.split('_')[0] + \"_\" + filename.split('_')[1]\n",
    "                    elif len(split) == 2:\n",
    "                        category = filename.split('_')[0]\n",
    "                    idx = idx + 1\n",
    "                    y.append(idx)\n",
    "    print(len(images), \"Images loaded successfully!\")\n",
    "    return images, filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_retrieval_k(train_data, test_data, train_names, test_names, train_images_as_array, test_images_as_array, k=20, view_option=0, image_size=(32,32), border_size=20):\n",
    "    avg_precisions = []\n",
    "    avg_recalls = []\n",
    "    precisionsatk = []\n",
    "    count = 0\n",
    "    \n",
    "    for idx, query in enumerate(test_data):\n",
    "        \n",
    "        all_precisions = []\n",
    "        all_recalls = []\n",
    "        precisions = []\n",
    "        recalls = []\n",
    "\n",
    "        # Finding the euclidean distance from the query image and sorting them into index\n",
    "        query = query.reshape((1, -1))\n",
    "        D = euclidean_distances(train_data, query).squeeze()\n",
    "        index = np.argsort(D)\n",
    "        \n",
    "        # Finding the index of the last correct image in the sorted index to iter to\n",
    "        last_correct_image_idx = 0\n",
    "        for i in range(len(index)):\n",
    "            if train_names[index[i]] == test_names[idx]:\n",
    "                last_correct_image_idx = i\n",
    "        \n",
    "        # make sure we iter to k (for precision@k) if all correct images are found before k\n",
    "        if k > last_correct_image_idx:\n",
    "            last_correct_image_idx = k+1\n",
    "        \n",
    "        # Itering through all images untill we get to k or last correct image to compute AP\n",
    "        for kk in range(1, last_correct_image_idx+2):\n",
    "            TP = 0\n",
    "            FP = 0\n",
    "            FN = 0\n",
    "            \n",
    "            # Finding the correct amount of images in the training set\n",
    "            correct_count = 0\n",
    "            for ind in index:\n",
    "                if train_names[ind] == test_names[idx]:\n",
    "                    correct_count += 1\n",
    "            sized_index = index[:kk]\n",
    "            \n",
    "            # Find TP FP FN\n",
    "            for ind in sized_index:\n",
    "                if train_names[ind] == test_names[idx]:\n",
    "                    TP += 1\n",
    "                else:\n",
    "                    FP += 1\n",
    "            FN = correct_count - TP\n",
    "            \n",
    "            # If we want to view the images then we run this code, else its a waste of computational time\n",
    "            if view_option == 1:\n",
    "                # Creating image of k images (including query image at start)\n",
    "                tmp = [query.reshape(image_size)]\n",
    "                for ind in sized_index[:k]:\n",
    "                    tmp.append(train_data[ind].reshape(image_size))\n",
    "                output = np.array(tmp)*255\n",
    "                output = output.transpose(1, 0, 2)\n",
    "                output = output.reshape((image_size[0], -1))\n",
    "                im_query = Image.fromarray(output)\n",
    "            \n",
    "            # If the last k image is a correct image we add precision to the list\n",
    "            if train_names[sized_index[-1]] == test_names[idx]:\n",
    "                precisions.append(TP/(TP+FP))\n",
    "                recalls.append(TP/(TP+FN))\n",
    "\n",
    "            # Adding all precisions and recalls to a seperate list\n",
    "            all_precisions.append(TP/(TP+FP))\n",
    "            all_recalls.append(TP/(TP+FN))\n",
    "        \n",
    "     \n",
    "        # Solving AP, AR and precision@k\n",
    "        avg_precisions.append(np.average(precisions))\n",
    "        avg_recalls.append(np.average(all_recalls))\n",
    "        precisionsatk.append(all_precisions[k-1])\n",
    "        \n",
    "        # Set a viewing option, if 1 we print out the following:\n",
    "        if view_option == 1:\n",
    "            display(im_query) \n",
    "            print(\"Label: {}\".format(test_names[idx]))\n",
    "            print(\"Average Precision for query {}: \".format(idx), avg_precisions[-1])\n",
    "            print(\"Precision@k for query {}: \".format(idx), precisionsatk[-1])\n",
    "            print(\"\\n\")\n",
    "        elif view_option == 0:\n",
    "            count += 1 \n",
    "            print(\"Percentage Complete: {}\".format(round((count/len(test_data))*100),2), end=\"\\r\")\n",
    "        elif view_option == 2:\n",
    "            # Allowing a view_option 2 -> for viewing top k images from non_pixel value inputs\n",
    "            # creating an array of the top k similar images\n",
    "            top_k_images = [test_images_as_array[idx]]\n",
    "            for i in range(0,k):\n",
    "                top_k_images.append(train_images_as_array[index[i]])\n",
    "\n",
    "            fig, axes = plt.subplots(1, k+1, figsize=(200/k, 200/k))\n",
    "            for i, (image, ax) in enumerate(zip(top_k_images, axes.ravel())):\n",
    "                # convert image to RGB and add border:\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                # resize image if border size greater than 10:\n",
    "                if border_size >= 10:\n",
    "                    image = cv2.resize(image, (250, 400), interpolation=cv2.INTER_CUBIC)\n",
    "                if i == 0:\n",
    "                    query_name = test_names[idx]\n",
    "                    title = \"Query: {}\".format(query_name)\n",
    "                    color = (0, 255, 0)\n",
    "                    image = border(image, color, border_size)\n",
    "                else:\n",
    "                    title = train_names[sized_index[i-1]]\n",
    "                    if train_names[sized_index[i-1]] == query_name:\n",
    "                        color = (0, 255, 0)\n",
    "                        image = border(image, color, border_size)\n",
    "                    else:\n",
    "                        color = (255, 0, 0)\n",
    "                        image = border(image, color, border_size)\n",
    "                # display all set options\n",
    "                ax.imshow(image, cmap=\"gray\")\n",
    "                ax.set_title(title)\n",
    "                ax.axis(\"off\")\n",
    "            plt.show()\n",
    "            print(\"Label: {}\".format(test_names[idx]))\n",
    "            print(\"Average Precision for query {}: \".format(idx), avg_precisions[-1])\n",
    "            print(\"Precision@k for query {}: \".format(idx), precisionsatk[-1])\n",
    "            print(\"\\n\")\n",
    "        elif view_option == 3:\n",
    "            top_k_images = [test_images_as_array[idx]]\n",
    "            for i in range(0,k):\n",
    "                top_k_images.append(train_images_as_array[index[i]])\n",
    "\n",
    "            fig, axes = plt.subplots(1, k+1, figsize=(200/k, 200/k))\n",
    "            for i, (image, ax) in enumerate(zip(top_k_images, axes.ravel())):\n",
    "                # convert image to RGB and add border:\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                # resize image if border size greater than 10:\n",
    "                if border_size >= 10:\n",
    "                    image = cv2.resize(image, (250, 400), interpolation=cv2.INTER_CUBIC)\n",
    "                if i == 0:\n",
    "                    query_name = test_names[idx]\n",
    "                    title = \"Query: {}\".format(query_name)\n",
    "                else:\n",
    "                    title = train_names[sized_index[i-1]]\n",
    "                    if train_names[sized_index[i-1]] == query_name:\n",
    "                        color = (0, 255, 0)\n",
    "                        image = border(image, color, border_size)\n",
    "                    else:\n",
    "                        color = (255, 0, 0)\n",
    "                        image = border(image, color, border_size)\n",
    "                # display all set options\n",
    "                ax.imshow(image, cmap=\"gray\")\n",
    "                ax.set_title(title)\n",
    "                ax.axis(\"off\")\n",
    "            plt.show()\n",
    "    return avg_precisions, avg_recalls, precisionsatk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save metrics data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_to_csv(_precisionsatk, _AP, _k, _dataset_name):\n",
    "    data = {'Precision@k': _precisionsatk, 'Average Precision': _AP}\n",
    "    df = pandas.DataFrame(data=data)\n",
    "    pandas.set_option(\"display.max_rows\", 500, \"display.max_columns\", 4)\n",
    "    df.to_csv('{}-metrics_k={}.csv'.format(_dataset_name, _k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving pixel values for oxford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pixel_values(test_gray_images, train_gray_images):\n",
    "    test_pixels = []\n",
    "    for image in test_gray_images:\n",
    "        img = Image.fromarray(image)\n",
    "        img = img.resize((100,100))\n",
    "        img = np.array(img)\n",
    "        img = img.reshape((10000,))\n",
    "        test_pixels.append(img)\n",
    "\n",
    "    train_pixels = []\n",
    "    for image in train_gray_images:\n",
    "        img = Image.fromarray(image)\n",
    "        img = img.resize((100,100))\n",
    "        img = np.array(img)\n",
    "        img = img.reshape((10000,))\n",
    "        train_pixels.append(img)\n",
    "    \n",
    "    return test_pixels, train_pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving pixel values for mpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mpeg_find_pixel_values(images):\n",
    "    tmp = []\n",
    "    for image in images:\n",
    "        im = np.asarray(image)\n",
    "        im = im.reshape((1024,))\n",
    "        tmp.append(im)\n",
    "    pixel_values = np.array(tmp)\n",
    "    return pixel_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting a border around an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def border(img, color, border_size):\n",
    "    # get dimensions\n",
    "    h, w = img.shape[0:2]\n",
    "\n",
    "    # make a base slightly bigger than image\n",
    "    base_size= h+(border_size*2), w+(border_size*2), 3\n",
    "    base = np.zeros(base_size, dtype=np.uint8)\n",
    "\n",
    "    # make a boundary of chosen color\n",
    "    cv2.rectangle(base, (0,0), (w+20,h+20), color, 30)\n",
    "\n",
    "    # put original image into base\n",
    "    base[border_size:h+border_size, border_size:w+border_size] = img\n",
    "    plt.imshow(base)\n",
    "    \n",
    "    return base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving SIFT + BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SIFT(images):\n",
    "    sift = cv2.SIFT_create()\n",
    "    \n",
    "    keypoints_per_image = []\n",
    "    descriptor_per_image = []\n",
    "    \n",
    "    count = 0\n",
    "    for image in images:\n",
    "        keypoints, descriptor = sift.detectAndCompute(image, None)\n",
    "\n",
    "        keypoints_per_image.append(keypoints)\n",
    "        descriptor_per_image.append(descriptor)\n",
    "        \n",
    "        count += 1 \n",
    "        print(\"Percentage Completed: {}%\".format(round((count/len(images))*100), 2), end=\"\\r\")\n",
    "    \n",
    "    print(\"\")\n",
    "    return keypoints_per_image, descriptor_per_image\n",
    "\n",
    "def stack_descriptors(descriptors):\n",
    "    stack = []\n",
    "    \n",
    "    for desc in descriptors:\n",
    "        tmp = np.array(desc)\n",
    "        if tmp.shape:\n",
    "            stack.append(tmp)\n",
    "            \n",
    "    all_descriptors = np.vstack(i for i in stack)\n",
    "    \n",
    "    return all_descriptors\n",
    "\n",
    "def cluster(data, n_clusters=100, cluster_type=\"minibatch\"):\n",
    "    start = time.time()\n",
    "    \n",
    "    if cluster_type == \"minibatch\":\n",
    "        cluster = MiniBatchKMeans(n_clusters=n_clusters)\n",
    "        y_cluster = cluster.fit(data)\n",
    "    elif cluster_type == \"kmeans\":\n",
    "        cluster = KMeans(n_clusters=n_clusters)\n",
    "        y_cluster = cluster.fit(data)\n",
    "    else:\n",
    "        print(\"Unknown cluster_type! Try: 'minibatch' or 'kmeans'\")\n",
    "        \n",
    "    end = time.time()\n",
    "    print(\"Time Elapsed: {} min\".format(round((end - start)/60, 2)))\n",
    "    return y_cluster\n",
    "\n",
    "def solve_BoW(descriptors, y_cluster, n_clusters):\n",
    "    previous = 0\n",
    "    count = 0\n",
    "    image_words = []\n",
    "    for image_number in range(len(descriptors)):\n",
    "        if descriptors[image_number] is not None:\n",
    "            tmp = []\n",
    "            for kp in descriptors[image_number]:\n",
    "                cluster = y_cluster.predict(np.array([kp]))\n",
    "                tmp.append(cluster[0])\n",
    "            image_words.append(tmp)\n",
    "            \n",
    "            count += 1\n",
    "            print(\"(1/2) Percentage Completed: {}%\".format(round((count/len(descriptors))*100), 2), end=\"\\r\")\n",
    "        else:\n",
    "            # If image has no desciptors, append 0 words to it\n",
    "            image_words.append([0])\n",
    "    \n",
    "    print(\"\")\n",
    "    count = 0\n",
    "    image_histograms = []\n",
    "    for image in range(len(image_words)):\n",
    "        hist = np.zeros(n_clusters)\n",
    "        for words in image_words[image]:\n",
    "            hist[words-1] = hist[words-1]+1\n",
    "        image_histograms.append(hist)\n",
    "        \n",
    "        count += 1\n",
    "        print(\"(2/2) Percentage Completed: {}%\".format(round((count/len(image_words))*100), 2), end=\"\\r\")\n",
    "    \n",
    "    print(\"\")\n",
    "    # Transforming data using tf-idf:\n",
    "    transformer = TfidfTransformer(smooth_idf=False)\n",
    "    weighted_image_histograms = transformer.fit_transform(image_histograms).toarray()\n",
    "    \n",
    "    return weighted_image_histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oxford 5k dataset func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Oxford5k_Image_Retrieval(images_path, gt_path, pixelorsift=\"sift\", savedata=0, n_clusters=100, k=10, view_option=2):\n",
    "    if pixelorsift == \"pixel\":\n",
    "        # Load in data\n",
    "        print(\"Loading Images...\")\n",
    "        test_gray_images, test_colour_images, test_names, test_imgs_path = load_test_data(images_path, gt_path)\n",
    "        train_gray_images, train_colour_images, train_names = load_train_data(images_path, gt_path, test_imgs_path)\n",
    "        \n",
    "        # Compute pixel values\n",
    "        print(\"\\nComputing Pixel Values...\")\n",
    "        test_pixels, train_pixels = find_pixel_values(test_gray_images, train_gray_images)\n",
    "        \n",
    "        # Compute metrics\n",
    "        print(\"\\nComputing Metics...\")\n",
    "        AP, AR, precisionsatk = image_retrieval_k(train_pixels, test_pixels, train_names, test_names, train_colour_images, test_colour_images, k, view_option, border_size=20)\n",
    "\n",
    "        # Display mAP\n",
    "        mAP = np.average(AP)\n",
    "        print(\"\\nmAP =\", mAP)\n",
    "        \n",
    "        # Save data\n",
    "        if savedata == 1:\n",
    "            save_data_to_csv(precisionsatk, AP, k, \"Oxford5k_pixelvalues\")\n",
    "            print(\"\\nData saved to csv\")\n",
    "        \n",
    "    elif pixelorsift == \"sift\":\n",
    "        # Load in data\n",
    "        print(\"Loading Images...\")\n",
    "        test_gray_images, test_colour_images, test_names, test_imgs_path = load_test_data(images_path, gt_path)\n",
    "        train_gray_images, train_colour_images, train_names = load_train_data(images_path, gt_path, test_imgs_path)\n",
    "        \n",
    "        # Copmuting bovw\n",
    "        print(\"\\nComputing test SIFT features...\")\n",
    "        test_kp, test_desc = SIFT(test_gray_images)\n",
    "        print(\"\\nComputing train SIFT features...\")\n",
    "        train_kp, train_desc = SIFT(train_gray_images)\n",
    "        stacked_train_desc = stack_descriptors(train_desc)\n",
    "        \n",
    "        print(\"\\nClustering Descriptors...\")\n",
    "        cluster_func = cluster(stacked_train_desc, n_clusters)\n",
    "        \n",
    "        print(\"\\nComputing test BoVW...\")\n",
    "        test_bovw  = solve_BoW(test_desc, cluster_func, n_clusters)\n",
    "        print(\"\\nComputing train BoVW...\")\n",
    "        train_bovw = solve_BoW(train_desc, cluster_func, n_clusters)\n",
    "        \n",
    "        # Compute metrics\n",
    "        print(\"\\nComputing Metrics...\")\n",
    "        AP, AR, precisionsatk = image_retrieval_k(train_bovw, test_bovw, train_names, test_names, train_colour_images, test_colour_images, k, view_option, border_size=20)\n",
    "        \n",
    "        # Display mAP\n",
    "        mAP = np.average(AP)\n",
    "        print(\"\\nmAP =\", mAP)\n",
    "        \n",
    "        # Save data\n",
    "        if savedata == 1:\n",
    "            save_data_to_csv(precisionsatk, AP, k, \"Oxford5k_BoVW_{}\".format(n_clusters))\n",
    "            print(\"\\nData saved to csv\")\n",
    "\n",
    "    else:\n",
    "        print(\"3rd input must be either: \\\"pixel\\\" or \\\"sift\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPEG7 dataset func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MPEG_Image_Retrieval(images_folder, pixelorsift=\"sift\", savedata=0, n_clusters=100, k=10, view_option=2):\n",
    "    if pixelorsift == \"pixel\":\n",
    "        # Load data\n",
    "        print(\"Loading data...\")\n",
    "        mpeg_images, filenames = load_MPEG7_data(images_folder, \".gif\", False)\n",
    "        \n",
    "        # Compute Pixel Values\n",
    "        print(\"\\nComputing Pixel Values...\")\n",
    "        pixel_values = mpeg_find_pixel_values(mpeg_images)\n",
    "        \n",
    "        # Split data\n",
    "        mpeg_train_pixels, mpeg_test_pixels, mpeg_train_names, mpeg_test_names, mpeg_train_images, mpeg_test_images = train_test_split(pixel_values, filenames, mpeg_images, test_size=0.2, random_state=43)\n",
    "\n",
    "        # Compute metrics\n",
    "        print(\"\\nComputing Metics...\")\n",
    "        AP, AR, precisionsatk = image_retrieval_k(mpeg_train_pixels, mpeg_test_pixels, mpeg_train_names, mpeg_test_names, mpeg_train_images, mpeg_test_images, k, view_option, border_size=5)\n",
    "\n",
    "        # Display mAP\n",
    "        mAP = np.average(AP)\n",
    "        print(\"\\nmAP =\", mAP)\n",
    "        \n",
    "        # Save data\n",
    "        if savedata == 1:\n",
    "            save_data_to_csv(precisionsatk, AP, k, \"MPEG7_pixelvalues\")\n",
    "            print(\"\\nData saved to csv\")\n",
    "    \n",
    "    elif pixelorsift == \"sift\":\n",
    "        # Load data\n",
    "        print(\"Loading data...\")\n",
    "        mpeg_images, filenames = load_MPEG7_data(images_folder, \".gif\", False)\n",
    "        \n",
    "        # Split data\n",
    "        mpeg_train, mpeg_test, mpeg_train_names, mpeg_test_names, mpeg_train_images, mpeg_test_images = train_test_split(mpeg_images, filenames, mpeg_images, test_size=0.2, random_state=42) \n",
    "        \n",
    "        # Compute bovw\n",
    "        print(\"\\nComputing test SIFT features...\")\n",
    "        test_kp, test_desc = SIFT(mpeg_test)\n",
    "        print(\"\\nComputing train SIFT features...\")\n",
    "        train_kp, train_desc = SIFT(mpeg_train)\n",
    "        stacked_train_desc = stack_descriptors(train_desc)\n",
    "        \n",
    "        print(\"\\n\\nCalculating For {} number of words!\".format(n_clusters))\n",
    "        print(\"\\nClustering Descriptors...\")\n",
    "        cluster_func = cluster(stacked_train_desc, n_clusters)\n",
    "\n",
    "        print(\"\\nComputing test BoVW...\")\n",
    "        test_bovw  = solve_BoW(test_desc, cluster_func, n_clusters)\n",
    "        print(\"\\nComputing train BoVW...\")\n",
    "        train_bovw = solve_BoW(train_desc, cluster_func, n_clusters)\n",
    "\n",
    "        # Compute metrics\n",
    "        print(\"\\nComputing Metics...\")\n",
    "        AP, AR, precisionsatk = image_retrieval_k(train_bovw, test_bovw, mpeg_train_names, mpeg_test_names, mpeg_train_images, mpeg_test_images, k, view_option, border_size=5)\n",
    "\n",
    "        # Display mAP\n",
    "        mAP = np.average(AP)\n",
    "        print(\"\\n\\nmAP =\", mAP)\n",
    "\n",
    "        # Save data\n",
    "        if savedata == 1:\n",
    "            save_data_to_csv(precisionsatk, AP, k, \"MPEG7_BoVW_{}\".format(n_clusters))\n",
    "            print(\"\\nData saved to csv\")\n",
    "\n",
    "    else:\n",
    "        print(\"2nd input must be either: \\\"pixel\\\" or \\\"sift\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable descriptions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "images_folder -> path to directory with all MPEG7 images\n",
    "\n",
    "images_path -> path to directory with all oxford building images\n",
    "\n",
    "gt_path -> path to directory with all ground truth files\n",
    "\n",
    "pixelorsift -> Choose either \"pixel\" or \"sift\", runs that code\n",
    "\n",
    "savedata -> Saves metrics to csv\n",
    "\n",
    "n_clusters -> number of words for SIFT\n",
    "\n",
    "k -> number of returned images (also k images checked in precision at k)\n",
    "\n",
    "view_option:\n",
    " - 0 -> returns only mAP\n",
    " - 1 -> returns merged images and metrics (only for database of same sized images) (doesnt work with SIFT)\n",
    " - 2 -> returns images and metrics (coloured, any size, labelled)\n",
    " - 3 -> returns images only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MPEG Code:\n",
    "images_folder = r\"C:\\Users\\Sean\\Desktop\\University Yr2\\project\\Image-Retrival (clean)\\MPEG7\\MPEG7\"\n",
    "pixelorsift = \"pixel\"\n",
    "savedata = 0\n",
    "n_clusters = 1000\n",
    "k = 10\n",
    "view_option = 3\n",
    "\n",
    "MPEG_Image_Retrieval(images_folder, pixelorsift, savedata, n_clusters, k, view_option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Oxford Code:\n",
    "images_path = r\"C:\\Users\\Sean\\Desktop\\University Yr2\\project\\Image-Retrival (clean)\\SIFT\\Oxford building images\"\n",
    "gt_path = r\"C:\\Users\\Sean\\Desktop\\University Yr2\\project\\Image-Retrival (clean)\\SIFT\\Ground Truth files\"\n",
    "pixelorsift = \"sift\"\n",
    "savedata = 0\n",
    "n_clusters = 100\n",
    "k = 10\n",
    "view_option = 3\n",
    "\n",
    "Oxford5k_Image_Retrieval(images_path, gt_path, pixelorsift, savedata, n_clusters, k, view_option)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vizualize from own BoVW NPY files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = r\"C:\\Users\\Sean\\Desktop\\University Yr2\\project\\Image-Retrival (clean)\\SIFT\\Oxford building images\"\n",
    "gt_path = r\"C:\\Users\\Sean\\Desktop\\University Yr2\\project\\Image-Retrival (clean)\\SIFT\\Ground Truth files\"\n",
    "\n",
    "train_bovw = np.load(\"SIFT/NPY files for BoVW/bovw files for 100000 Words/BoW_Train.npy\")\n",
    "test_bovw = np.load(\"SIFT/NPY files for BoVW/bovw files for 100000 Words/BoW_Test.npy\")\n",
    "\n",
    "test_gray_images, test_colour_images, test_names, test_imgs_path = load_test_data(images_path, gt_path)\n",
    "train_gray_images, train_colour_images, train_names = load_train_data(images_path, gt_path, test_imgs_path)\n",
    "\n",
    "k = 10\n",
    "view_option = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AP, AR, precisionsatk = image_retrieval_k(train_bovw, test_bovw, train_names, test_names, train_colour_images, test_colour_images, k, view_option)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
