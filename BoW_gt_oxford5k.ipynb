{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_retrieval_k(train_data, test_data, train_names, test_names, train_images_as_array, test_images_as_array, k=10, view_option=1):\n",
    "    avg_precisions = []\n",
    "    avg_recalls = []\n",
    "    precisionsatk = []\n",
    "    count = 0\n",
    "    \n",
    "    for idx, query in enumerate(test_data):\n",
    "        \n",
    "        all_precisions = []\n",
    "        all_recalls = []\n",
    "        precisions = []\n",
    "        recalls = []\n",
    "\n",
    "        # Finding the euclidean distance from the query image and sorting them into index\n",
    "        query = query.reshape((1, -1))\n",
    "        D = euclidean_distances(train_data, query).squeeze()\n",
    "        index = np.argsort(D)\n",
    "        \n",
    "        # Finding the index of the last correct image in the sorted index to iter to\n",
    "        last_correct_image_idx = 0\n",
    "        for i in range(len(index)):\n",
    "            if train_names[index[i]] == test_names[idx]:\n",
    "                last_correct_image_idx = i\n",
    "        \n",
    "        # make sure we iter to k (for precision@k) if all correct images are found before k\n",
    "        if k > last_correct_image_idx:\n",
    "            last_correct_image_idx = k+1\n",
    "        \n",
    "        # Itering through all images untill we get to k or last correct image to compute AP\n",
    "        for kk in range(1, last_correct_image_idx+2):\n",
    "            TP = 0\n",
    "            FP = 0\n",
    "            FN = 0\n",
    "            \n",
    "            # Finding the correct amount of images in the training set\n",
    "            correct_count = 0\n",
    "            for ind in index:\n",
    "                if train_names[ind] == test_names[idx]:\n",
    "                    correct_count += 1\n",
    "            sized_index = index[:kk]\n",
    "            \n",
    "            # Find TP FP FN\n",
    "            for ind in sized_index:\n",
    "                if train_names[ind] == test_names[idx]:\n",
    "                    TP += 1\n",
    "                else:\n",
    "                    FP += 1\n",
    "            FN = correct_count - TP\n",
    "            \n",
    "            # If the last k image is a correct image we add precision to the list\n",
    "            if train_names[sized_index[-1]] == test_names[idx]:\n",
    "                precisions.append(TP/(TP+FP))\n",
    "                recalls.append(TP/(TP+FN))\n",
    "\n",
    "            # Adding all precisions and recalls to a seperate list\n",
    "            all_precisions.append(TP/(TP+FP))\n",
    "            all_recalls.append(TP/(TP+FN))\n",
    "        \n",
    "     \n",
    "        # Solving AP, AR and precision@k\n",
    "        avg_precisions.append(np.average(precisions))\n",
    "        avg_recalls.append(np.average(all_recalls))\n",
    "        precisionsatk.append(all_precisions[k-1])\n",
    "        \n",
    "        # View options\n",
    "        if view_option == 0:\n",
    "            count += 1 \n",
    "            clear_output(wait=True)\n",
    "            print(\"Percentage Complete: {}\".format((count/len(test_data))*100))\n",
    "        elif view_option == 1:\n",
    "            # creating an array of the top k similar images\n",
    "            top_k_images = [test_images_as_array[idx]]\n",
    "            for i in range(0,k):\n",
    "                top_k_images.append(train_images_as_array[index[i]])\n",
    "\n",
    "            fig, axes = plt.subplots(1, k+1, figsize=(200/k, 200/k))\n",
    "            for i, (image, ax) in enumerate(zip(top_k_images, axes.ravel())):\n",
    "                ax.imshow(image)\n",
    "                if i == 0:\n",
    "                    ax.set_title(\"Query: {}\".format(test_names[idx]))\n",
    "                else:\n",
    "                    ax.set_title(train_names[sized_index[i-1]])\n",
    "                ax.axis(\"off\")\n",
    "            plt.show()\n",
    "            \n",
    "            print(\"Label: {}\".format(test_names[idx]))\n",
    "            print(\"Average Precision for query {}: \".format(idx), avg_precisions[-1])\n",
    "            print(\"Precision@k for query {}: \".format(idx), precisionsatk[-1])\n",
    "            print(\"\\n\")\n",
    "        \n",
    "    return avg_precisions, avg_recalls, precisionsatk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_to_csv(_precisionsatk, _AP, _k, _dataset_name):\n",
    "    data = {'Precision@k': _precisionsatk, 'Average Precision': _AP}\n",
    "    df = pandas.DataFrame(data=data)\n",
    "    pandas.set_option(\"display.max_rows\", 500, \"display.max_columns\", 4)\n",
    "    df.to_csv('{}-metrics_k={}.csv'.format(_dataset_name, _k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_in(images_path, gt_path, end_fname):\n",
    "    \n",
    "    image_paths = []\n",
    "    names = []\n",
    "    image_dict = {}\n",
    "    colour = []\n",
    "    seen_names = []\n",
    "    \n",
    "    for filename in sorted(os.listdir(gt_path)):\n",
    "        if filename.endswith(end_fname[0]) or filename.endswith(end_fname[1]):\n",
    "\n",
    "            # Saving filename\n",
    "            tmp = filename.split(\".\")[0].split(\"_\")\n",
    "            if len(tmp) == 4:\n",
    "                name = tmp[0]+\"_\"+tmp[1]\n",
    "            elif len(tmp) == 3:\n",
    "                name = tmp[0]   \n",
    "\n",
    "            # Reading the image number to be saved\n",
    "            with open(os.path.join(gt_path, filename), \"r\") as f:\n",
    "                line = f.readlines()\n",
    "                for i in range(len(line)):\n",
    "                    line[i] = line[i][:-1]\n",
    "                    # Check if image has already been added:\n",
    "                    if line[i] not in seen_names:\n",
    "                        # Append this many names\n",
    "                        names.append(name)\n",
    "                        seen_names.append(line[i])\n",
    "                        image_paths.append(line[i])\n",
    "\n",
    "    for idx, img in enumerate(image_paths):\n",
    "        name = names[idx]\n",
    "\n",
    "        if end_fname[1] != \"ok.txt\":\n",
    "            img = img.split(\" \")[0][5:]\n",
    "            image = cv2.imread(images_path + \"/\" + img + \".jpg\")\n",
    "        else:\n",
    "            image = cv2.imread(images_path + \"/\" + img + \".jpg\")\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        if gray_image is not None:\n",
    "            if name in image_dict:\n",
    "                image_dict[name].append(gray_image)\n",
    "            else:\n",
    "                image_dict[name] = [gray_image]\n",
    "        colour.append(image)\n",
    "    \n",
    "    print(\"Loaded in: {} Images, {} Names, {} Classes\".format(len(colour), len(names), len(image_dict)))\n",
    "    return image_dict, colour, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sift_features(images):\n",
    "    sift_vectors = {}\n",
    "    descriptor_list = []\n",
    "    \n",
    "    sift = cv2.SIFT_create()\n",
    "    for key,value in images.items():\n",
    "        features = []\n",
    "        for img in value:\n",
    "            kp, des = sift.detectAndCompute(img,None)\n",
    "            \n",
    "            descriptor_list.extend(des)\n",
    "            features.append(des)\n",
    "            \n",
    "        sift_vectors[key] = features\n",
    "    return [descriptor_list, sift_vectors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(k, descriptor_list):\n",
    "    start = time.time()\n",
    "    \n",
    "    k_means = KMeans(n_clusters = k, n_init=10)\n",
    "    k_means.fit(descriptor_list)\n",
    "    \n",
    "    end = time.time()\n",
    "    print(\"Time Elapsed: {} min\".format(round((end - start)/60, 2)))\n",
    "    \n",
    "    return k_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bow(all_bovw, n_clusters):\n",
    "    dict_feature = {}\n",
    "    \n",
    "    for key,value in all_bovw.items():\n",
    "        category = []\n",
    "        \n",
    "        for img in value:\n",
    "            histogram = np.zeros(n_clusters)\n",
    "            \n",
    "            for each_feature in img:\n",
    "                ind = k_means.predict([each_feature])\n",
    "                histogram[ind] += 1\n",
    "            category.append(histogram)\n",
    "        dict_feature[key] = category\n",
    "        \n",
    "    return dict_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_array(diction):\n",
    "    array = []\n",
    "    for key, value in diction.items():\n",
    "        for img in value:\n",
    "            array.append(img)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for computing BoW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loding in images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputs for the function:\n",
    "- images_path -> the path to folder of the 5k oxford dataset (all images)\n",
    "- gt_path -> the path to folder of the ground truth files (for queries, and good/ok related images)\n",
    "- end_fname -> the gt file name endings:\n",
    "    - ['query.txt', 'none'] -> used to find the query files\n",
    "    - ['good.txt', 'ok.txt'] -> used to find the good/ok related image files\n",
    "    \n",
    "Returns:\n",
    "- image_dict -> dictionary of the images (whether test or training) split based on class\n",
    "- colour -> Array of the corresponding images saved in image_dict (these are the colour images)\n",
    "- names -> Array of the corresponding names for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = r\"C:\\Users\\Sean\\Desktop\\Image-Retrieval\\Oxford code\\Oxford dataset\\Oxford building images\"\n",
    "gt_path = r\"C:\\Users\\Sean\\Desktop\\Image-Retrieval\\Oxford code\\Ground Truth files\"\n",
    "\n",
    "test, test_colour, test_names = load_images_in(images_path, gt_path, ['query.txt', 'none'])\n",
    "train, train_colour, train_names = load_images_in(images_path, gt_path, ['good.txt', 'ok.txt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving SIFT Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the train and test data is split into 2 parts!\\\n",
    "I used cv2's SIFT function\n",
    "\n",
    "Inputs:\n",
    "- images -> gray_scale images in split dictionary form (filenames as keys)\n",
    "\n",
    "Returns:\n",
    "- [descriptor_list, sift_vectors]:\n",
    "    - descriptor_list -> array of all descriptors stacked without seperation\n",
    "    - sift_vectors -> dictionary of the descriptors split into classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sifts = sift_features(train) \n",
    "descriptor_list = sifts[0] \n",
    "all_bovw_feature = sifts[1] \n",
    "\n",
    "test_bovw_feature = sift_features(test)[1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only clustering the training images sift features!\\\n",
    "Predict the test features as new unseen data, which makes sense to show the algorithm unseen data so it doesn't overfit!\\\n",
    "Using Kmeans clustering as achieves best results (does take long however)\n",
    "\n",
    "Inputs:\n",
    "- k -> number of clusters (or the number of visual words wanted)\n",
    "- descriptor_list -> Array of training sift feature descriptors (test not included!)\n",
    "\n",
    "Outputs:\n",
    "- k_means -> the kmeans algorithm (used for prediction of test/query images later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 100\n",
    "k_means = kmeans(n_clusters, descriptor_list) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating BoW "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a histogram of visual word length (or the number of clusters in the kmeans algorithm)\n",
    "\n",
    "Inputs:\n",
    "- all_bovw -> descriptors split by classes\n",
    "- n_clusters -> number of clusters (number of visual words)\n",
    "\n",
    "Outputs:\n",
    "- dict_feature -> Dictionary of histograms split by classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bovw_train = create_bow(all_bovw_feature, n_clusters) \n",
    "bovw_test = create_bow(test_bovw_feature, n_clusters) \n",
    "\n",
    "bovw_train = dict_to_array(bovw_train)\n",
    "bovw_test = dict_to_array(bovw_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input:  \n",
    "- train_data -> Training data\n",
    "- test_data -> Testing data\n",
    "- train_names -> Corresponding training names\n",
    "- test_names -> Corresponding testing names\n",
    "- train_images_as_array -> Corresponding training images (for viewing)\n",
    "- test_images_as_array -> Corresponding testing images (for viewing)\n",
    "- k -> How many top k images to show, also to solve precision at that k value\n",
    "- veiw_option:\n",
    "    - 0 -> Displays nothing, returns results.\n",
    "    - 1 -> Displays the top k labelled images, AP and precision@k for each query image\n",
    "\n",
    "Output:\n",
    "- avg_precisions -> A list of all AP results\n",
    "- avg_recalls -> A list of all AR results\n",
    "- precisionatk -> list of precisions@k for inputted k value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "view_option = 1\n",
    "\n",
    "AP, AR, precisionsatk = image_retrieval_k(bovw_train, bovw_test, train_names, test_names, train_colour, test_colour, k, view_option)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing mAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our Average Precisions from computing metrics, we define the success of the retieval system based on a singular result which is the average of all the AP per query: Named mAP (Mean Average Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mAP = np.average(AP)\n",
    "print(\"mAP: \", mAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving to file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the precision at k and average precisions for each query image for a set k value.\\\n",
    "Saves to the working directory as an csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"gt_oxford5k_BoW_{}\".format(n_clusters)\n",
    "save_data_to_csv(precisionsatk, AP, k, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mAP values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The csv file saved doesn't inlcude mAP results (so I have recorded them manualy here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10        words: 0.24385\\\n",
    "100       words: 0.32494\\\n",
    "1000      words: \\\n",
    "10,000    words: \\\n",
    "100,000   words: \\\n",
    "1,000,000 words: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
